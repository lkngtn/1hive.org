The [technological singularity](https://en.wikipedia.org/wiki/Technological_singularity) will occur when technological growth becomes uncontrollable and irreversible, resulting in unforeseeable changes to human civilization. Its arguable when exactly this point happened, or will happen, but regardless the rate of technological growth appears to be accelerating exponentially. 

One important milestone that is widely associated with the singularity is the development of artificial general intelligence (AGI). [This milestone is predicted to be achieved alarmingly soon](https://www.metaculus.com/questions/3479/date-weakly-general-ai-is-publicly-known/). 

Once we have AGI we can and almost certainly will end up massively scaling the amount of intelligence we collectively apply to technological advancement. We will invent new things, and with each new thing we may unlock yet unimaginable utility or catastrophic harm. 

We might be able to cure all diseases, including aging. We might unlock nearly unlimited energy and reverse global warming. We might be able to expand throughout the galaxy, or simply explore an infinite number of virtual worlds. 

But what happens when productivity is almost purely a function of capital rather than human input? How does our society change and adapt as we find ourselves becoming increasingly obsolete? How do we ensure that the artificial intelligences that we create remain aligned with our collective interests as a species?

We could have everything we could ever want, or go extinct, all possibly within the next decade. I'm optimistic that we can nudge things in the right direction so that [[together we thrive]].




